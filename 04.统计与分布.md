# 统计与分布

## 加和值、平均值和标准差

### 加和值

**加和** 其实就是统计学最基础的体现。使用一个性状数值的加和值来对一群事物进行描述是一种非常自然的描述方式。

### 平均值

**平均** 就是最一组数据整体的感性认识。像这类使用单一数据定义来概括性描述一些抽象或复杂数据的方式叫做“指标”。平均值就是最常用的指标之一。

### 标准差

$$\sigma=\sqrt[2]{{1\over n} \sum_{i=1}^n (X_i-\bar{X})^2}$$

**标准差** 用来描述整体数据的波动趋势

## 加权均值

**权**指的是权重，也就是指所占的“比重”或“重要”程度

## 众数、中位数

**众数**就是样本对象中出现最多的数据。

**中位数**就是样本数据按照一定的顺序排列后位于中间位置的数字。

## 欧式距离

之前计算标准差的公式中，每个样本数据减去平均值，在将差值平方，开方。实际上，这个过程就是在计算欧氏距离。

**欧式距离**就是在一个 $N$ 维空间，求两点的距离，这个距离肯定是一个大于等于零的数字，计算这个距离就需要两个点在各自维度上的坐标相减，平方后再开方。

### 欧式距离的计算公式

$$d = \sqrt{(x_1-x_2)^2}$$

$$d = \sqrt{(x_1-x_2)^2+ (y_1-y_2)^2}$$

$$d = \sqrt{(x_1-x_2)^2+ (y_1-y_2)^2 + (z_1 - z_2)^2}$$

## 曼哈顿距离

**曼哈顿距离**也叫出租车距离，用来标明两个点在标准坐标系上的绝对轴距总和。由赫尔曼提出，他曾是爱因斯坦的老师，四维时空理论的创立者。

### 曼哈顿距离计算公式

$$c=|x_1 - x_2|$$

$$c=|x_1 - x_2| + |y_1 - y_2|$$

$$c=|x_1 - x_2| + |y_1 - y_2| + |z_1 - z_2|$$

> 与欧式距离一样，哈曼顿距离同样是个非负数，都是为了描述两点之间的距离。
>
> 不同的是，哈曼顿距离只需要做加减法，这使得在大量计算过程中代价更低，而且会消除开平方过程中带来的误差。

## 同比、环比

**同比**就是与相邻时段的同一时期相比。

**环比**就是与上一个报告期相比。

## 抽样

**抽样**是一种非常好的了解大量样本空间分布情况的方法。样本越大则抽样带来的成本减少的收益约明显。

## 高斯分布

**高斯分布**即正态分布，是一个在数学、物理及工程等领域都非常重要的概率分布。

高斯分布的概率密度函数：

$${f(x)} = {1 \over {\sqrt{2\pi\sigma^2}}} {exp {({-{(x-u)^2} \over {2\sigma^2}})}}$$

### 概率密度函数

$y = f(x)$ 这种表达式表示函数值 $y$ 和自变量 $x$ 函数关系，$f(x)$ 展开之后就具体解释了 $x$ 参数运算的过程。

而概率密度实际指的就是 $y=f(x)$， $x$是样本特性自变量， $y$ 是 $x$ 在这个样本特性上的数量比例。$exp$ 指的是自然常数 $e$ 的幂函，即 $e$ 的多少次幂的概念。

这个函数的峰值在 $x=\mu$ 的位置，此时对应的函数值 $y$ 为 $1\over \sqrt{2\pi}\sigma$。

- $\mu$ 较大，则整个函数图像中轴向右偏移
- $\mu$ 较小，则整个函数图像中轴向左偏移
- $\sigma$ 较大，则整个函数图像曲线绵延比较长，坡度比较平缓
- $\sigma$ 较小，则整个函数图像曲线绵延比较短，坡度比较陡

这里样本数量的计算用的是定积分的定义，即整个函数曲线在其下方与 $y=0$（x 轴）围住的区域的面积占比。它在 $x=\mu$ 左右两侧的函数是对称的， $x$ 在 $\mu-\sigma$ 和 $\mu+\sigma$ 之间的样本数量占到整个样本数量的 68.2%， $x$ 在 $\mu-2\sigma$ 和 $\mu+2\sigma$ 之间的样本数量找你到整个样本数量的 95.4%， $x$ 在 $\mu-3\sigma$ 和 $\mu+3\sigma$ 之间的样本数量占到整个样本数量的 99.6%。

## 泊松分布

**泊松分布**是一种统计与概率学中常见的离散概率分布。

### 泊松分布的概率函数

$${P(X=k)}={{ \lambda^k\over k! } e^{-\lambda}}， k=0,1,2,3,...$$

泊松分布的参数 $\lambda$ 是单位时间（或单位面积）内随机事件的平均发生率。

泊松分布适合于描述单位时间内随机事件发生的次数。

泊松分布也就是说在一个标准时间段内，发生这件事情的次数为 $\lambda$ 次，那么发生 $k$ 次的概率为多少。

### 举个例子

公交站每 5 分钟会来 2 辆车，求 5 分钟内来 5 辆的概率。

这里 $\lambda$ 为 2， $k$ 为 5

$$P(X=k=5)= {{2^5 \over {5!}}e^{-2}}\approx0.316$$

泊松分布使用的事件需要满足以下 3 个条件:

- 小概率事件
- 事件独立，不会相互影响
- 事件的概率稳定

可以看到一个现象。$k$ 每增加 1， 在 $k$ 小于 $\lambda$ 的时候，累积函数增加的非常快，而且，每次增加的量都比上次增加的要多；在 $k$ 越过 $\lambda$ 之后，虽然每次依然都在增加，但是每次的增加量越来越少。

## 伯努利分布

**伯努利分布**是一种离散分布。

### 泊松伯努利分布的分布律

$$
P_n={\begin{cases}
p &&n=1 \\
1-p &&n=0
\end{cases}}$$

也可以写作：
$$

P(n)=P^n(1-p)^{1-n}

$$
伯努利分布的应用需要满足一下条件：

- 各次试验中的事件相互独立的，每一次 $n=1$ 和 $n=0$ 的概率分别为 $p$ 和 $q$；
- 每次试验都只有两个结果，即 $n=0$， 或 $n=1$；

满足伯努利分布的样本有一个非常重要的性质，即满足下面公式：
$$

P(X=k)=C_n^k \cdot p^k(1-p)^{n-k}

$$
其中，X 指的是试验次数，$C^k_n$ 指的是组合，也就是 ${n! \over {k!(n-k)!}}$，$p^k(1-p)^{n-k}$就是 $p$ 的 $n$ 次幂与 $(1-p)$ 的 $n-k$ 次幂的乘积。

这个公式表示，如果一个试验满足 $P(n)={p^n(1-p)^{1-n}}$ 的伯努利分布，那么在连续试验 $n$ 次的情况下，出现 $n=1$ 的情况发生恰好 $k$ 次的概率为
$C_n^k \cdot p^k(1-p)^{n-k}$。 $n=1$ 就是对应概率为 $p$ 的情况
$$
